{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICA 2: Clasificador de tweets\n",
    "\n",
    "En esta práctica desarrollaremos un script que se encargará de extraer información de la red social Twitter. En concreto, obtendrá los tweets de dos usuarios indicados y los almacenará en disco para, posteriormente, trabajar con ellos realizando experimentos de clasificación y análisis de sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, importaremos los módulos de Python que nos harán falta para poder realizar el script. Los módulos son los siguientes:\n",
    "\n",
    "+ twitter: Twitter API wrapper para Python.\n",
    "+ ElementTree: Módulo que nos permitirá crear y leer XML.\n",
    "+ CountVectorizer y TfidfVectorizer: Módulos de scikit-learn que utilizaremos para extraer características numéricas de un corpus.\n",
    "+ model_selection: Módulo de scikit-learn que utilizaremos para obtener los conjuntos de entrenamiento y test.\n",
    "+ SVC: Módulo de scikit-learn que utilizaremos para realizar la clasificación.\n",
    "+ confusion_matrix: Módulo de scikit-learn que utilizaremos para mostrar la matriz de confusión.\n",
    "+ twokenize: Módulo tokenizador de tweets.\n",
    "+ pandas: Módulo de análisis de datos (sólo lo utilizaremos para obtener una representación más vistosa de la matriz de confusión)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importamos el wrapper del API de twitter\n",
    "import twitter\n",
    "# Importamos el parser XML\n",
    "import xml.etree.ElementTree as ET\n",
    "# Importamos sys y getopt para poder obtener los parametros de entrada del script\n",
    "import sys, getopt\n",
    "# Importamos el CountVectorizer y el TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# Importamos model_selection para realizar el split entre muestras de entrenamiento y de test\n",
    "from sklearn import model_selection\n",
    "# Importamos SVC para realizar la clasificacion\n",
    "from sklearn.svm import SVC\n",
    "# Importamos confusion_matrix para obtener la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Importamos twokenize para usarlo como tokenizador de tweets\n",
    "import twokenize\n",
    "# Importamos pandas para la representacion en linea de comandos de la matriz de confusion como una tabla\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definiremos los valores necesarios para realizar la conexión al API de Twitter. Además, crearemos variables con los valores usuarios de los que obtendremos los tweets, el número máximo de tweets que se pueden recuperar en una única petición, el tipo de vectorizador a usar, el tokenizador y el nombre del fichero donde se guardarán los tweets extraídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definicion de constantes como las credenciales, el maximo de tweets por peticion, valores por defecto...\n",
    "CONSUMER_KEY = 'wo8oNmaGUcpF9WGckt62FtHUc'\n",
    "CONSUMER_SECRET = 'do4NPAweukb41Y8qQZkpGT5IRUiKEAv6MrzYv8tl8u3NDcSK2P'\n",
    "ACCESS_TOKEN = '2214334652-k6o6ODLsraogVDrcAF39hMo020aBLvwzNUF8DLl'\n",
    "ACCESS_TOKEN_SECRET = 'odpZZyOlsB0TowICtmEC5LjINAIDSzHjVQolUKi6NAsZi'\n",
    "\n",
    "MAX_TWEETS_PER_REQUEST = 200\n",
    "\n",
    "VECTORIZER = 'tf-idf'\n",
    "TOKENIZER = 'twokenize'\n",
    "\n",
    "USER_1 = 'Pontifex'\n",
    "USER_2 = 'DalaiLama'\n",
    "N = 1200\n",
    "\n",
    "# Nombre de fichero donde se guardaran los datos extraidos de twitter\n",
    "FILENAME = 'pyTweetClassifier_data.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También encapsularemos en funciones alguna de las funcionalidades que necesitaremos. Las funciones son las siguientes:\n",
    "\n",
    "+ get_user_time_line: Función que descarga n tweets más recientes del usuario indicado.\n",
    "+ get_XML_from_tweet: Función que, dado un tweet, crea un elemento ElementTree que formará parte de un XML.\n",
    "+ get_XML_content_as_list_from_file: Función que lee un XML de tweets de un fichero y devuelve un diccionario cuya clave es el nombre de usuario y el valor una lista de sus tweets.\n",
    "+ get_vectorizer: Función que devuelve un vectorizador del tipo que se le indique ('tf-idf' para TfidfVectorizer o 'count' para CountVectorizer, en otro caso devuelve None).\n",
    "+ get_train_and_test_samples: Función que, a partir de un corpus de tweets, lo divide en dos partes. La primera parte, con un 80% de los tweets, será el conjunto de entrenamiento. La segunda, con el 20% restante, será el de test. Además devolverá los resultados para los dos conjuntos (a que usuario pertenece cada tweet).\n",
    "+ get_positives_and_negatives: Función que toma un corpus de tweets y un lexicon y devuelve el número total de palabras, el número de palabras positivas y el de negativas (cada uno de estos valores será un diccionario en el que la clave será el nombre de usuario de los tweets y el valor el número de palabras correspondiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crear metodo de descarga de tweets que tenga en cuenta las limitaciones de la API\n",
    "def get_user_time_line(api, user, n = MAX_TWEETS_PER_REQUEST):\n",
    "    result = None\n",
    "    if(n <= MAX_TWEETS_PER_REQUEST):\n",
    "        result = api.GetUserTimeline(screen_name=user, count=n)\n",
    "    else:\n",
    "        result = []\n",
    "        requests = n//MAX_TWEETS_PER_REQUEST if (n%MAX_TWEETS_PER_REQUEST == 0) else (n//MAX_TWEETS_PER_REQUEST) + 1\n",
    "        max_id = None\n",
    "        for count in range(1, requests+1):\n",
    "            if(n < count*MAX_TWEETS_PER_REQUEST):\n",
    "                res = api.GetUserTimeline(screen_name=user, count=n%MAX_TWEETS_PER_REQUEST, max_id=max_id)\n",
    "                max_id = res[-1].id\n",
    "                result = result + res\n",
    "            else:\n",
    "                res = api.GetUserTimeline(screen_name=user, count=MAX_TWEETS_PER_REQUEST, max_id=max_id)\n",
    "                max_id = res[-1].id\n",
    "                result = result + res\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta función es necesario tener en cuenta el número de tweets que se desea obtener. Si este número es mayor de MAX_TWEETS_PER_REQUEST (200), se deberán hacer múltiples peticiones para obtener todos los datos especificando el id del último tweet recuperado como max_id en la nueva petición. De esta forma, la nueva petición sólo recuperará los tweets anteriores al tweet cuyo id se ha especificado.\n",
    "\n",
    "En cuanto a las limitaciones del API sobre el número de peticiones que se pueden realizar en cierta ventana temporal, el wrapper Python-Twitter permite indicar una opción en su inicialización (se podrá ver más adelante en este notebook) para que sea él mismo el encargado de espaciarlas debidamente y cumplir con las restricciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que parsea un tweet a XML y devuelve un elemento ElementTree\n",
    "def get_XML_from_tweet(tweet):\n",
    "    e = ET.Element('tweet')\n",
    "    text = ET.SubElement(e, 'text')\n",
    "    text.text = tweet.text\n",
    "    user = ET.SubElement(e, 'user')\n",
    "    user.text = tweet.user.screen_name\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que lee un XML de tweets de un fichero y devuelve un diccionario cuya clave es el nombre de usuario y el valor una lista de sus tweets\n",
    "def get_XML_content_as_list_from_file(filename):\n",
    "    parser = ET.XMLParser(encoding = 'utf-8')\n",
    "    root = ET.parse(filename, parser = parser).getroot()\n",
    "    result = {}\n",
    "    for entry in root:\n",
    "        if entry.find('text').text != None and entry.find('user').text != None:\n",
    "            result[entry.find('user').text] = result[entry.find('user').text] if entry.find('user').text in result else []\n",
    "            result[entry.find('user').text].append(entry.find('text').text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que devuelve un vectorizador del tipo que se le indique\n",
    "def get_vectorizer(key='tf-idf', tokenizer=None):\n",
    "    tok = None\n",
    "    if(tokenizer != None and tokenizer == 'twokenize'):\n",
    "        tok = twokenize.tokenizeRawTweetText\n",
    "    if(key == 'tf-idf'):\n",
    "        return TfidfVectorizer(stop_words='english', tokenizer=tok, min_df=5)\n",
    "    elif(key == 'count'):\n",
    "        return CountVectorizer(stop_words='english', tokenizer=tok, min_df=5)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar en esta función que se ha sobrescrito el tokenizador a la hora de crear el vectorizador. Como esta vectorización se va a hacer sobre tweets, se ha decidido utilizar el módulo twokenizer para realizar la tokenización ya que está especialmente diseñado para este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que, a partir de un corpus de tweets, devuelve muestras de entrenamiento y test ademas de sus resultados (a que clase pertenece cada muestra)\n",
    "def get_train_and_test_samples(corpus):\n",
    "    user_class = 0\n",
    "    tweets = []\n",
    "    results = []\n",
    "    for user, l in corpus.items():\n",
    "        for tweet in l:\n",
    "            tweets.append(tweet)\n",
    "            results.append(user_class)\n",
    "        user_class = user_class + 1\n",
    "\n",
    "    return model_selection.train_test_split(tweets, results, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion que, a partir de un corpus de tweets y un lexicon, devuelve el numero total de terminos, el numero de positivos y el de negativos\n",
    "def get_positives_and_negatives(corpus, lexicon):\n",
    "    num_words = {}\n",
    "    num_positive_words = {}\n",
    "    num_negative_words = {}\n",
    "    for user, l in corpus.items():\n",
    "        for tweet in l:\n",
    "            for token in twokenize.tokenizeRawTweetText(tweet):\n",
    "                num_words[user] = num_words[user] if user in num_words else 0\n",
    "                num_words[user] = num_words[user] + 1\n",
    "                if token in lexicon['positive']:\n",
    "                    num_positive_words[user] = num_positive_words[user] if user in num_positive_words else 0\n",
    "                    num_positive_words[user] = num_positive_words[user] + 1\n",
    "                elif token in lexicon['negative']:\n",
    "                    num_negative_words[user] = num_negative_words[user] if user in num_negative_words else 0\n",
    "                    num_negative_words[user] = num_negative_words[user] + 1\n",
    "    return num_words, num_positive_words, num_negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta función también se usa el módulo twokenize para tokenizar cada uno de los tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definidas las funciones, es el momento de ejecutar el código que extraerá los datos de Twitter de los dos usuarios especificados anteriormente. El primer paso será realizar la conexión al API de Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                      consumer_secret=CONSUMER_SECRET,\n",
    "                      access_token_key=ACCESS_TOKEN,\n",
    "                      access_token_secret=ACCESS_TOKEN_SECRET,\n",
    "                      sleep_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha comentado anteriormente, es en este paso en el que es necesario especificar que sea el wrapper el encargado de espaciar las peticiones. Esto se logra indicando el parámetro sleep_on_rate_limit con valor _True_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el elemento root del XML. El XML resultante tendrá un aspecto como este:\n",
    "\n",
    "<pre>\n",
    "&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n",
    "&lt;tweetList&gt;\n",
    "  &lt;tweet&gt;\n",
    "    &lt;text&gt;When we encounter others, do we bring them the warmth of charity or do we stay closed up and warm only ourselves before our fireplace?&lt;/text&gt;\n",
    "    &lt;user&gt;Pontifex&lt;/user&gt;\n",
    "  &lt;/tweet&gt;\n",
    "  &lt;tweet&gt;\n",
    "    &lt;text&gt;May Mary's pure and simple smile be a source of joy for each one of us as we face life&amp;#8217;s difficulties.&lt;/text&gt;\n",
    "    &lt;user&gt;Pontifex&lt;/user&gt;\n",
    "  &lt;/tweet&gt;\n",
    "  [...]\n",
    "    &lt;tweet&gt;\n",
    "    &lt;text&gt;Webcast: His Holiness the Dalai Lama's Tibetan New Year Message http://bit.ly/bFcZMc&lt;/text&gt;\n",
    "    &lt;user&gt;DalaiLama&lt;/user&gt;\n",
    "  &lt;/tweet&gt;\n",
    "  &lt;tweet&gt;\n",
    "    &lt;text&gt;His Holiness the Dalai Lama in Los Angeles - 21 February 2010 http://bit.ly/cRGXyr&lt;/text&gt;\n",
    "    &lt;user&gt;DalaiLama&lt;/user&gt;\n",
    "  &lt;/tweet&gt;\n",
    "&lt;/tweetList&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = ET.Element('tweetList')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada usuario, recuperamos una lista de tweets de su timeline e iteramos sobre ella creando en cada iteración un elemento &lt;tweet&gt; que contendrá el nombre de usuario y su tweet. Estos elementos se añaden a medida que se crean como hijos de &lt;tweetList&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in get_user_time_line(api, USER_1, N):\n",
    "    e.append(get_XML_from_tweet(tweet))\n",
    "for tweet in get_user_time_line(api, USER_2, N):\n",
    "    e.append(get_XML_from_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras recuperar el contenido y haber formado el XML, lo escribimos en un fichero local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(FILENAME, 'w')\n",
    "print(ET.tostring(e).decode('utf-8'), file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la información debidamente normalizada y almacenada, procederemos a trabajar con ella.\n",
    "<br/>\n",
    "Empezaremos recuperando la información del XML y creando un diccionario con los tweets de cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recuperamos el contenido del fichero\n",
    "corpus = get_XML_content_as_list_from_file(FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso será obtener los conjuntos de entrenamiento y test (con una proporción 80%-20%) así como sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtenemos los conjuntos de entrenamiento y test\n",
    "xTrain, xTest, yTrain, yTest = get_train_and_test_samples(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación obtenemos el vectorizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtenemos el vectorizador a partir de los parametros indicados\n",
    "vectorizer = get_vectorizer(VECTORIZER, TOKENIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el vectorizador con el conjunto de entrenamiento y obtenemos el vector de tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos el vectorizador con el conjunto de entrenamiento y obtenemos el vector de tfidf\n",
    "xTrainVect = vectorizer.fit_transform(xTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un primer clasificador SVC indicando unos parámetros aleatorios y observamos su comportamiento. Los parámetros elegidos para esta primera aproximación son C = 1.0, kernel = 'rbf', gamma = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el clasificador con el conjunto de entrenamiento vectorizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el vector de tfidf para el conjunto de test y utilizamos el clasificador para predecir los resultados para dicho conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtenemos el vector de tfidf para el conjunto de test\n",
    "xTestVect = vectorizer.transform(xTest)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los resultados obtenidos, obtenemos la matriz de confusión y el valor de accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>213</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             213              14\n",
       "Real Positivo               9             244"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque se puede observar que el porcentaje de acierto con este caso es bueno. Es interesante jugar con los parámetros disponibles para crear el clasificador y así poder comparar sus resultados. Por lo tanto, se mostrarán algunas variantes del código anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 3.5, kernel = 'rbf', gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>214</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>8</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             214              13\n",
       "Real Positivo               8             245"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=3.5, kernel='rbf', gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.62%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 7.0, kernel = 'rbf', gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>214</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>8</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             214              13\n",
       "Real Positivo               8             245"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=7.0, kernel='rbf', gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.62%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 1.0, kernel = 'linear', gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>214</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             214              13\n",
       "Real Positivo               9             244"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=1.0, kernel='linear', gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.42%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 3.5, kernel = 'linear', gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>218</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             218               9\n",
       "Real Positivo               9             244"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=3.5, kernel='linear', gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.25%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 7.0, kernel = 'linear', gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>213</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>13</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             213              14\n",
       "Real Positivo              13             240"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=7.0, kernel='linear', gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.38%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 3.5, kernel = 'poly', degree=2, gamma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>212</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             212              15\n",
       "Real Positivo               9             244"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=3.5, kernel='poly', degree=2, gamma=1.0)\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que utilizando valores de C y kernels diferentes se obtienen valores de accuracy parecidos pero no iguales. Para intentar buscar la mejor configuración para el clasificador podemos realizar lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edgar/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/edgar/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparametros:  {'C': 1.0, 'degree': 1, 'gamma': 0.89999999999999991, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Importamos el modulo GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# Importamos numpy\n",
    "import numpy as np\n",
    "# Indicamos los hiperparametros que queremos evaluar\n",
    "hyperParams = {'C': np.arange(1.0, 3.5, 0.5), \n",
    "               'kernel': ['linear', 'poly', 'rbf'],\n",
    "               'degree': np.arange(1, 4, 1),\n",
    "               'gamma': np.arange(0.5, 1.5, 0.2)}\n",
    "# Creamos el clasificador\n",
    "modelCV = GridSearchCV(SVC(), hyperParams, cv=4, scoring='accuracy')\n",
    "# Lo entrenamos\n",
    "modelCV.fit(xTrainVect, yTrain)\n",
    "# Obtenemos los mejores hiperparametros\n",
    "print(\"Mejores hiperparametros: \", modelCV.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos los parámetros obtenidos para realizar la clasificación como en los casos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. Negativo</th>\n",
       "      <th>Pred. Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real Negativo</th>\n",
       "      <td>213</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. Negativo  Pred. Positivo\n",
       "Real Negativo             213              14\n",
       "Real Positivo               9             244"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el clasificador a partir de los parametros indicados\n",
    "clf = SVC(C=modelCV.best_params_['C'], kernel=modelCV.best_params_['kernel'], gamma=modelCV.best_params_['gamma'], degree=modelCV.best_params_['degree'])\n",
    "# Entrenamos el clasificador con el conjunto de entrenamiento vectorizado\n",
    "clf.fit(xTrainVect, yTrain)\n",
    "# Predecimos los resultados del conjunto de test\n",
    "yTestPred = clf.predict(xTestVect)\n",
    "matrix = confusion_matrix(yTest, yTestPred)\n",
    "pd.DataFrame(matrix, ['Real Negativo', 'Real Positivo'], ['Pred. Negativo', 'Pred. Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(clf.score(xTestVect, yTest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, GridSearch no tiene por qué devolver unos parámetros que proporcionen el mayor valor de accuracy al predecir los resultados del conjunto de test. Sin embargo, como se hace uso de validación cruzada, si que podemos confiar en que los parámetros son fiables y pueden dar buenos valores para diferentes conjuntos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar un análisis de los datos obtenidos podemos llegar a la conclusión de que, a través del clasificador SVC, se puede realizar una clasificación de los tweets de dos usuarios obteniendo un nivel bastante alto de fiabilidad. En este caso en concreto, se han utilizado los tweets de dos líderes religiosos, que son el Papa Francisco y el Dalai Lama. Como la temática de sus tweets suele ser parecida, se podría llegar a pensar que sería un inconveniente para el clasificador. Sin embargo, su valor de accuracy se sitúa por encima del 95% en la mayoría de los casos. Por lo tanto, este ejemplo parece una buena métrica para medir el buen hacer del clasificador y podemos pensar que, con usuarios de perfil más variado, sus resultados serían todavía mejores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se hará un pequeño experimento de análisis de sentimiento básico en el que, utilizando un lexicon de términos positivos y negativos, se medirá la positividad/negatividad de los tweets de cada usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se recupera el lexicon con los términos positivos y negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recuperamos el lexicon de terminos positivos y negativos\n",
    "pos_neg_words = {'positive': [], 'negative': []}\n",
    "\n",
    "for pos_word in open('positive-words.txt', 'r').readlines()[35:]:\n",
    "    pos_neg_words['positive'].append(pos_word.rstrip())\n",
    "\n",
    "for neg_word in open('negative-words.txt', 'r').readlines()[35:]:\n",
    "    pos_neg_words['negative'].append(neg_word.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación obtenemos para cada usuario el número total de palabras de su conjunto de tweets, el número de palabras positivas y el número de negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words, positives, negatives = get_positives_and_negatives(corpus, pos_neg_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, con los datos obtenidos en el paso anterior, podemos obtener los porcentajes de términos positivos y negativos para cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de terminos positivos para el usuario Pontifex: 5.55%\n",
      "Porcentaje de terminos negativos para el usuario Pontifex: 2.51%\n",
      "\n",
      "Porcentaje de terminos positivos para el usuario DalaiLama: 6.95%\n",
      "Porcentaje de terminos negativos para el usuario DalaiLama: 2.03%\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de terminos positivos para el usuario {}: {:.2f}%'.format(USER_1, positives[USER_1]*100/num_words[USER_1]))\n",
    "print('Porcentaje de terminos negativos para el usuario {}: {:.2f}%'.format(USER_1, negatives[USER_1]*100/num_words[USER_1]))\n",
    "print()\n",
    "print('Porcentaje de terminos positivos para el usuario {}: {:.2f}%'.format(USER_2, positives[USER_2]*100/num_words[USER_2]))\n",
    "print('Porcentaje de terminos negativos para el usuario {}: {:.2f}%'.format(USER_2, negatives[USER_2]*100/num_words[USER_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que en ambos casos el porcentaje de términos positivos es mayor que el de términos negativos. Esto nos hace pensar que la mayoría de los tweets de estos usuarios transmiten mensajes positivos, lo que concuerda con su perfil (líder religioso). Como mejora para obtener porcentajes mayores en el análisis de sentimiento se podrían filtrar stopwords, ya que tienen una ocurrencia alta y provocan que el cómputo total de palabras sea muy elevado. De todas formas, sin este filtrado y teniendo en cuenta lo anterior, los resultados obtenidos son suficientemente significativos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
