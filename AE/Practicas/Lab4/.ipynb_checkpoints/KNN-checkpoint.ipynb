{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain [[-1.67705098 -1.34890655]\n",
      " [ 1.67705098 -1.34890655]\n",
      " [-1.11803399  0.79708114]\n",
      " [ 1.11803399  0.79708114]\n",
      " [ 0.55901699 -0.12262787]\n",
      " [-0.55901699 -0.73576721]\n",
      " [-0.55901699  1.41022048]\n",
      " [ 0.55901699  1.41022048]] \n",
      "xTest [[-0.55901699 -0.12262787]\n",
      " [ 0.55901699 -0.73576721]] \n",
      "yTrain [ 0.  1.  0.  1.  1.  0.  0.  1.] \n",
      "yTest [ 0.  1.]\n",
      "-----------------------------------\n",
      "[[-1.67705098 -1.34890655]\n",
      " [ 1.67705098 -1.34890655]\n",
      " [-1.11803399  0.79708114]\n",
      " [ 1.11803399  0.79708114]\n",
      " [ 0.55901699 -0.12262787]\n",
      " [-0.55901699 -0.73576721]\n",
      " [-0.55901699  1.41022048]\n",
      " [ 0.55901699  1.41022048]]\n",
      "[-3.  3. -2.  2.  1. -1. -1.  1.]\n",
      "-4.0\n",
      "4.0\n",
      "-5.0\n",
      "6.0\n",
      "Best hyperparameters {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "1.000 (+/-0.000) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "()\n",
      "1.000 (+/-0.000) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "()\n",
      "1.000 (+/-0.000) for {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "()\n",
      "1.000 (+/-0.000) for {'n_neighbors': 2, 'weights': 'distance'}\n",
      "()\n",
      "0.875 (+/-0.217) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "()\n",
      "1.000 (+/-0.000) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "()\n",
      "0.875 (+/-0.217) for {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "()\n",
      "1.000 (+/-0.000) for {'n_neighbors': 4, 'weights': 'distance'}\n",
      "()\n",
      "220000\n",
      "220000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n55Y8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd94e79210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9a40af1dcefd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnNeighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0myPred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mtestErrList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myPred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/classification.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             )\n\u001b[1;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 9"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "datasetName = 'toyExample.data'\n",
    "datasetDelimiter = ','\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(datasetName, delimiter=datasetDelimiter)\n",
    "# separate the data from the target attributes\n",
    "xRaw = dataset[:,0:dataset.shape[1]-1]\n",
    "y = dataset[:,dataset.shape[1]-1]\n",
    "# missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "xPrep = imp.fit_transform(xRaw)\n",
    "#Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(xPrep)\n",
    "x=scaler.transform(xPrep)\n",
    "\n",
    "#Divide in training and test, shuffling the examples and keeping the proportion of examples of each class\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print 'xTrain', xTrain, \"\\nxTest\", xTest, \"\\nyTrain\", yTrain, \"\\nyTest\", yTest\n",
    "\n",
    "\n",
    "#Generate the mesh\n",
    "h = .02  # step size in the mesh\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "print '-----------------------------------'\n",
    "print xTrain\n",
    "print scaler.inverse_transform(xTrain)[:, 0]\n",
    "x_min = scaler.inverse_transform(xTrain)[:, 0].min() - 1\n",
    "x_max = scaler.inverse_transform(xTrain)[:, 0].max() + 1\n",
    "y_min = scaler.inverse_transform(xTrain)[:, 1].min() - 1\n",
    "y_max = scaler.inverse_transform(xTrain)[:, 1].max() + 1\n",
    "print x_min\n",
    "print x_max\n",
    "print y_min\n",
    "print y_max\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "################################################################\n",
    "#KNN results\n",
    "################################################################\n",
    "\n",
    "#Generate grid search\n",
    "hyperParams = {'n_neighbors': range(1,5), \n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Classifier and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                     hyperParams, cv=4, scoring='accuracy')\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters\", modelCV.best_params_\n",
    "neighList, errList, devList = [], [], []\n",
    "for hyperP, mean_score, scores in modelCV.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std(), hyperP))\n",
    "    if hyperP['weights'] == modelCV.best_params_['weights']:\n",
    "        neighList.append(hyperP['n_neighbors'])\n",
    "        errList.append(1-mean_score)\n",
    "        devList.append(scores.std())\n",
    "    print()\n",
    "\n",
    "\n",
    "#Create an instance of Neighbors Classifier with the best hyperparameters and the full training set\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = modelCV.best_params_['n_neighbors'], \n",
    "                                       weights = modelCV.best_params_['weights'])\n",
    "model.fit(xTrain, yTrain)\n",
    "print len(xx.ravel())\n",
    "print len(yy.ravel())\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "\n",
    "#Plot also the training points\n",
    "plt.scatter(scaler.inverse_transform(xTrain)[:, 0], \n",
    "            scaler.inverse_transform(xTrain)[:, 1], \n",
    "            c=yTrain, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"k = %i, weights = '%s'\"\n",
    "          % (modelCV.best_params_['n_neighbors'], modelCV.best_params_['weights']))\n",
    "\n",
    "\n",
    "#Saving and re-loading the model\n",
    "joblib.dump(model, 'KNN_model.pkl') \n",
    "newModel = joblib.load('KNN_model.pkl')\n",
    "newModel.predict(xTest)\n",
    "plt.scatter(scaler.inverse_transform(xTest)[:, 0], \n",
    "                scaler.inverse_transform(xTest)[:, 1], \n",
    "                c=yTest, cmap=cmap_bold, marker = '1')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Test error\n",
    "testErrList=[]\n",
    "for nNeighbors in range(1,5):\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors = nNeighbors)\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPred=model.predict(xTest)\n",
    "    testErrList.append(1-metrics.accuracy_score(yTest,yPred))\n",
    "\n",
    "\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.errorbar(neighList, testErrList)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En este problema sólo se estandariza la entrada porque es de clasificación. En problemas de regresión, se debe estandarizar tanto la entrada como la salida.\n",
    "\n",
    "accuracy -> precisión en clasificación\n",
    "\n",
    "error en clasificación -> 1 - precisión en clasificación"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
